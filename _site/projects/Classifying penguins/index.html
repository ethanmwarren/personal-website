<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.551">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Chen Guan, Lucas MacHardy, Ethan Warren">
<meta name="dcterms.date" content="2022-06-02">
<meta name="description" content="Training a classical machine learning model to predict a penguin’s species from physical characteristics.">

<title>Penguins Classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
<meta name="citation_title" content="Penguins Classification">
<meta name="citation_author" content="Chen Guan, Lucas MacHardy, Ethan Warren">
<meta name="citation_publication_date" content="2022-06-02">
<meta name="citation_cover_date" content="2022-06-02">
<meta name="citation_year" content="2022">
<meta name="citation_online_date" content="2022-06-02">
<meta name="citation_language" content="en">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects/index.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-github" role="button" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-bi-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/ethanmwarren/personal-website">
 <span class="dropdown-text">Website Source Code</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/ethanmwarren">
 <span class="dropdown-text">Github Profile</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Penguins Classification</h1>
  <div class="quarto-categories">
    <div class="quarto-category">machine learning</div>
    <div class="quarto-category">science</div>
    <div class="quarto-category">unsupervised learning</div>
  </div>
  </div>

<div>
  <div class="description">
    Training a classical machine learning model to predict a penguin’s species from physical characteristics.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Chen Guan, Lucas MacHardy, Ethan Warren </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 2, 2022</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../projects/Classifying Penguins/penguins.jpg" class="img-fluid figure-img"></p>
<figcaption>Penguins</figcaption>
</figure>
</div>
<p><strong>Project Overview</strong></p>
<p>As part of an introductory Python class focused on machine learning, our team was tasked with a comprehensive project to classify penguin species using a provided dataset. The dataset contained various attributes of penguins, including but not limited to species type, body measurements (culmen length and depth, flipper length, body mass), and ecological data (island, region, sex, and isotopic composition). Our objective was to conduct a full analysis of this dataset, which entailed extensive data cleaning, handling missing values, and exploratory data analysis to identify significant features for model building.</p>
<p>The project’s phases were methodically structured: initially, we performed a thorough analysis to understand the data’s characteristics and distributions. This step was crucial for our subsequent data cleaning process, where we addressed missing entries and potential outliers to ensure the integrity of our modeling data. We then split the data into training and test sets to evaluate the performance and generalizability of our models.</p>
<p>In the modeling phase, we explored several algorithms including Multinomial Logistic Regression (MLR), Random Forest, and Support Vector Machines (SVM) to determine which model best fit our data. After a comparative analysis of each model’s performance, Multinomial Logistic Regression was selected as the most effective model based on its accuracy and the interpretability of its results. This model allowed us to classify the penguin species with a high degree of confidence, using the most predictive features derived from our exploratory analysis.</p>
<p>This project not only reinforced our understanding of machine learning concepts and techniques but also provided practical experience in data handling, feature selection, and model evaluation—essential skills for any aspiring data scientist.</p>
<p><strong>Data Used</strong></p>
<p>The project utilized the Palmer Penguins dataset, a compilation of 344 observations and 17 features including species classification, physical measurements (like culmen length and depth, flipper length, body mass), and ecological data (region, island, sex, dietary isotopes). However, to streamline our analysis and enhance the model’s performance, we refined the dataset by removing columns with excessive missing values or those less relevant for species classification such as comments, sample number, and date of egg collection. The cleansing process was carefully designed to retain potentially predictive attributes, ensuring a robust dataset for building our classification model.</p>
<p><strong>Tools and Technologies</strong></p>
<p>Our toolset for this project was selected to handle both data manipulation and machine learning tasks effectively:</p>
<ol type="1">
<li><strong>Python</strong> served as the programming language, providing a flexible and powerful base for data science operations.</li>
<li><strong>Sci-Kit Learn</strong> was employed for implementing and evaluating various machine learning models due to its extensive library of algorithms and preprocessing methods.</li>
<li><strong>NumPy</strong> and <strong>Pandas</strong> were crucial for data manipulation tasks, allowing for efficient handling and transformation of data structures.</li>
<li><strong>Matplotlib</strong> and <strong>Seaborn</strong> were used for exploratory data analysis, enabling us to visualize distributions and relationships in the data effectively, which informed subsequent feature selection and model tuning.</li>
</ol>
<p><strong>Methodology</strong></p>
<p>The methodology adopted for this project was meticulous and divided into several clear stages:</p>
<p><strong>1. Data Cleaning and Preprocessing</strong><br>
</p>
<p>Our team developed a function to clean and preprocess the dataset by dropping non-essential columns, encoding categorical variables, and since there weren’t many, dropping rows with any missing values. This process resulted in a concise dataset with 11 meaningful features, retaining only the rows that provided complete information.<br>
</p>
<p><strong>2. Data Splitting</strong><br>
</p>
<p>The data was split into an 80% training set and a 20% test set, and then each set was cleaned and preprocessed independently, ensuring that both sets reflected the full variety of data to avoid model bias.<br>
</p>
<p><strong>3. Exploratory Data Analysis (EDA)</strong><br>
</p>
<p>Prior to modeling, we conducted thorough exploratory analysis to understand the underlying patterns and relationships in the data. This analysis was pivotal in selecting the most informative features for the models.</p>
<p>The EDA began with grouping the dataset by species and sex to compute summary statistics for each group across all quantitative features. To visualize the relationships between variables, we utilized Seaborn’s pair plot tool, color-coding each of the three penguin species. This visualization helped us identify significant clusters, indicating strong differentiation potential between species based on certain feature combinations.</p>
<p>Notably, the relationships between culmen length vs.&nbsp;flipper length, body mass vs.&nbsp;culmen length, and culmen depth vs.&nbsp;culmen length exhibited distinct clusters that were promising for classification. Additionally, histograms for culmen length and culmen depth—grouped by species—revealed unique patterns. These distributions showed some overlap when considered individually but, when combined, suggested a high potential for accurately classifying species. We also examined these features split by sex, revealing further distinctions in measurements that could enhance our model’s predictive accuracy. The combination of culmen length and depth, in particular, emerged as critical: distinguishing between Adelie and the combined group of Chinstrap/Gentoo by culmen length, and between Gentoo and the combined group of Adelie/Chinstrap by culmen depth. This structured approach not only facilitated a thorough understanding of the dataset but also ensured that our machine learning models were built on a solid foundation of clean and relevant data.</p>
<p><strong>4. Feature Selection</strong><br>
</p>
<p>Informed by our EDA, we moved to feature selection, aiming to identify a compact set of features that could effectively predict penguin species. Given the patterns observed, we chose to focus on two quantitative features—culmen length and depth—and one qualitative feature—sex—as our primary predictors.</p>
<p>To refine our selection and validate the effectiveness of these features, we devised a function named comb_score. This function systematically tested combinations of these features across our three chosen models: Multinomial Logistic Regression, Random Forests, and Support Vector Machines. Employing cross-validation as part of our strategy allowed us to mitigate overfitting and ensure robustness in our model’s performance. Cross-validation was particularly vital, as it provided a more generalized understanding of model accuracy across multiple subsets of the data, rather than relying solely on a single train-test split.</p>
<p>This approach not only streamlined our feature set but also reinforced our model’s capacity to generalize well to new data, an essential aspect of successful machine learning applications. By the guidelines of the project, we were to select 2 quantitative variables and 1 qualitative variable. From the results of running this function, we found that the three most appropriate variables to include in the model were ‘Culmen Length’, ‘Culmen Depth’, and ‘Sex’.</p>
<p><strong>5. Modeling</strong></p>
<p>To analyze the data, we employed three distinct machine learning models using the Sci-kit Learn library: Multinomial Logistic Regression (MLR), Random Forest, and Support Vector Machines (SVM). Each model was evaluated for its effectiveness in classifying the species of penguins based on the selected features.</p>
<ol type="1">
<li><strong>Multinomial Logistic Regression (MLR):</strong> We began with the MLR model due to its robustness in handling multiclass classification problems. After training the model, we utilized a confusion matrix to assess its performance. The confusion matrix demonstrated perfect classification accuracy on the test set, with a cross-validation score of 0.988. Furthermore, we plotted decision regions to visualize the classification boundaries created by the model. These plots revealed that most data points were correctly classified, with only a few outliers, emphasizing the model’s overall high accuracy and reliability.</li>
<li><strong>Random Forest:</strong> Our next model was the Random Forest classifier. After training, similar evaluations were conducted. The confusion matrix indicated that the Random Forest model successfully predicted the species of 63 out of 64 penguins in the test set, only misclassifying a single Gentoo penguin as a Chinstrap. The cross-validation score for this model was 0.981. Decision region plots were again used to visualize the model’s performance, showing a high degree of accuracy, with minimal misclassification except for the noted outlier.</li>
<li><strong>Support Vector Machines (SVM):</strong> Finally, we trained the SVM model. This model yielded a cross-validation score of 0.827, significantly lower than the other two models. The confusion matrix revealed several misclassifications, particularly misidentifying 7 Gentoo penguins as Chinstrap. This issue was further explored through decision region plots, which highlighted a large overlap in the prediction regions, especially where the SVM used culmen depth as a key feature. It became evident that the model struggled with overlap in feature distributions, particularly for Gentoo penguins with culmen depths less than approximately 18-19 mm, leading to these misclassifications. Each model’s decision regions provided critical insights into how effectively each algorithm could delineate between species based on the given features. This comparison highlighted strengths and weaknesses in how each model handled the complexity of the dataset, guiding our ultimate choice of the best performing model for the final application.</li>
</ol>
<p><strong>Results</strong></p>
<ol type="1">
<li><p><strong>Multinomial Logistic Regression (MLR)</strong> The Multinomial Logistic Regression model achieved a cross-validation score of 0.988, indicating high accuracy in predicting penguin species based on culmen length, culmen depth, and sex. The confusion matrix confirmed that the model correctly classified all penguins in the test dataset. Despite a few points misclassified as outliers, the decision regions plot demonstrated that the model performs robustly across the dataset. This suggests that the MLR model is not overfitting, as it maintains consistent performance across training, cross-validation, and testing datasets, indicating good generalization to new data. Possible improvements could include expanding the dataset and incorporating more predictive features to enhance the model’s accuracy further.</p></li>
<li><p><strong>Random Forest</strong> The Random Forest model reported a cross-validation score of 0.981, showcasing its effectiveness in species classification using the same features as MLR. It misclassified only one penguin in the test set, suggesting it is almost as accurate as the MLR model. The decision regions plot indicated no signs of overfitting, with stable performance across different data splits. This model’s generalizability could potentially be improved through hyperparameter tuning, such as GridSearch or Bayesian optimization, to optimize performance.</p></li>
<li><p><strong>Support Vector Machines (SVM)</strong> The Support Vector Machines model lagged behind the other two, with a cross-validation score of 0.827. It incorrectly predicted the species of 7 out of 64 penguins in the test set, primarily confusing Gentoo penguins as Chinstrap. This issue was visible in the decision regions plot, where the model showed significant overlap in species classification. Despite its lower performance, the SVM model did not exhibit signs of overfitting and performed consistently across the training and testing datasets. Improvement could be achieved by expanding the number of qualitative variables used for prediction, which preliminary tests suggested might enhance accuracy.</p></li>
</ol>
<p>Overall Performance and Recommendations:<br>
The MLR and Random Forest models both achieved near-perfect prediction accuracy on the test data, making either model a strong candidate for practical applications. However, given its slightly higher cross-validation score and simpler structure, the MLR model is recommended as the primary choice. Its simplicity suggests better generalizability and lower computational overhead compared to the more complex Random Forest model.</p>
<p>In conclusion, while all three models performed commendably, the Multinomial Logistic Regression model, using culmen length, culmen depth, and sex as predictors, is selected as the optimal model for classifying penguin species due to its high accuracy and model simplicity.</p>
<p><strong>Challenges</strong></p>
<p>Throughout the project, we faced several challenges that tested our problem-solving and analytical skills. One of the primary challenges was working with these models in python, as they were all brand new to us as students. We conducted a lot of research and consulted the documentation from sci-kit learn heavily. Another challenge was determining the best methods for feature selection and model evaluation, especially in balancing model accuracy with the risk of overfitting. To tackle this, we were able to plot the decision regions of the model, which also gave us a lot of helpful insight into how the models were making their classifications, and where the cutoff for the features was. These challenges necessitated a thorough exploration of various statistical techniques and collaborative problem-solving to ensure the integrity and reliability of our findings.</p>
<p><strong>Teamwork</strong></p>
<p>The success of this project was largely due to effective teamwork and collaborative effort. All team members were actively involved in every phase of the project, from data acquisition and preparation to model evaluation and final discussions. In the initial stages, we jointly worked on cleaning the data, which involved rigorous discussions on handling missing values and deciding which features to modify or remove. During the data visualization phase, each of us contributed by coding at least one plot or table, ensuring diverse input in the discussion and interpretation of results.</p>
<p>Feature selection was a collective effort where we debated various approaches and jointly developed the cross-validation scoring function, primarily coded by Chen and Lucas. Model fitting and analysis were also collaborative, with Ethan (myself) taking the lead on coding the decision regions plots. We collectively analyzed the outputs, including confusion matrices and the implications of misclassifications by each model. Our final decision on the model selection was made unanimously, reflecting our cohesive approach to research and problem-solving.</p>
<p><strong>Conclusion</strong></p>
<p>This project not only enhanced our technical skills in data science and machine learning but also strengthened our ability to work as a team. Throughout the project, we successfully navigated challenges through mutual support and shared knowledge, which was crucial in achieving our objectives. The experience has prepared us well for future collaborative projects and professional challenges in the field of data science. Read my full report of the project <a href="../../Projects/Classifying Penguins/Final_Project-3.pdf" title="pdf">here</a>. And just for fun for reading this far, here is a <a href="https://youtu.be/o5QZz6KksvE?si=5YKH4VobQRGLwkrO" target="_blank">super cute video</a> of Gentoo Penguins building nests.</p>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>© 2024, Ethan Warren</p>
</div>
  </div>
</footer>




</body></html>