[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ethan Warren",
    "section": "",
    "text": "Hi, I’m Ethan, a 4th-year undergrad student at UCLA specializing in Statistics and Data Science, with a minor in Math. My academic journey has been an exhilarating blend of rigorous coursework, hands-on projects, and collaborative research, enabling me to develop a robust analytical skillset, proficiency in statistical software, and a deep understanding of data-driven decision-making processes.\nI’m excited by the recent developments in artificial intelligence and machine learning, and I’m eager to apply these fields in creative ways to solve complex problems. I’m passionate about leveraging data to solve real-world problems, optimize processes, and inform strategy. As I approach the culmination of my undergraduate studies, I’m eager to apply my skills in a dynamic environment that challenges me to grow and contribute to impactful projects. Here’s a link to my Resume.\nHead to my projects tab to learn more about some of the research and projects I’ve worked on that combine a lot of the things that fascinate me with AI and ML."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Ethan Warren",
    "section": "",
    "text": "Hi, I’m Ethan, a 4th-year undergrad student at UCLA specializing in Statistics and Data Science, with a minor in Math. My academic journey has been an exhilarating blend of rigorous coursework, hands-on projects, and collaborative research, enabling me to develop a robust analytical skillset, proficiency in statistical software, and a deep understanding of data-driven decision-making processes.\nI’m excited by the recent developments in artificial intelligence and machine learning, and I’m eager to apply these fields in creative ways to solve complex problems. I’m passionate about leveraging data to solve real-world problems, optimize processes, and inform strategy. As I approach the culmination of my undergraduate studies, I’m eager to apply my skills in a dynamic environment that challenges me to grow and contribute to impactful projects. Here’s a link to my Resume.\nHead to my projects tab to learn more about some of the research and projects I’ve worked on that combine a lot of the things that fascinate me with AI and ML."
  },
  {
    "objectID": "projects/Classifying_penguins/index.html",
    "href": "projects/Classifying_penguins/index.html",
    "title": "Penguins Classification",
    "section": "",
    "text": "Gentoo penguins playing in the snow.\n\n\nProject Overview\nAs part of an introductory Python class focused on machine learning, our team was tasked with a comprehensive project to classify penguin species using a provided dataset. The dataset contained various attributes of penguins, including but not limited to species type, body measurements (culmen length and depth, flipper length, body mass), and ecological data (island, region, sex, and isotopic composition). Our objective was to conduct a full analysis of this dataset, which entailed extensive data cleaning, handling missing values, and exploratory data analysis to identify significant features for model building.\nThe project’s phases were methodically structured: initially, we performed a thorough analysis to understand the data’s characteristics and distributions. This step was crucial for our subsequent data cleaning process, where we addressed missing entries and potential outliers to ensure the integrity of our modeling data. We then split the data into training and test sets to evaluate the performance and generalizability of our models.\nIn the modeling phase, we explored several algorithms including Multinomial Logistic Regression (MLR), Random Forest, and Support Vector Machines (SVM) to determine which model best fit our data. After a comparative analysis of each model’s performance, Multinomial Logistic Regression was selected as the most effective model based on its accuracy and the interpretability of its results. This model allowed us to classify the penguin species with a high degree of confidence, using the most predictive features derived from our exploratory analysis.\nThis project not only reinforced our understanding of machine learning concepts and techniques but also provided practical experience in data handling, feature selection, and model evaluation—essential skills for any aspiring data scientist.\nData Used\nThe project utilized the Palmer Penguins dataset, a compilation of 344 observations and 17 features including species classification, physical measurements (like culmen length and depth, flipper length, body mass), and ecological data (region, island, sex, dietary isotopes). However, to streamline our analysis and enhance the model’s performance, we refined the dataset by removing columns with excessive missing values or those less relevant for species classification such as comments, sample number, and date of egg collection. The cleansing process was carefully designed to retain potentially predictive attributes, ensuring a robust dataset for building our classification model.\nTools and Technologies\nOur toolset for this project was selected to handle both data manipulation and machine learning tasks effectively:\n\nPython served as the programming language, providing a flexible and powerful base for data science operations.\nSci-Kit Learn was employed for implementing and evaluating various machine learning models due to its extensive library of algorithms and preprocessing methods.\nNumPy and Pandas were crucial for data manipulation tasks, allowing for efficient handling and transformation of data structures.\nMatplotlib and Seaborn were used for exploratory data analysis, enabling us to visualize distributions and relationships in the data effectively, which informed subsequent feature selection and model tuning.\n\nMethodology\nThe methodology adopted for this project was meticulous and divided into several clear stages:\n1. Data Cleaning and Preprocessing\n\nOur team developed a function to clean and preprocess the dataset by dropping non-essential columns, encoding categorical variables, and since there weren’t many, dropping rows with any missing values. This process resulted in a concise dataset with 11 meaningful features, retaining only the rows that provided complete information.\n\n2. Data Splitting\n\nThe data was split into an 80% training set and a 20% test set, and then each set was cleaned and preprocessed independently, ensuring that both sets reflected the full variety of data to avoid model bias.\n\n3. Exploratory Data Analysis (EDA)\n\nPrior to modeling, we conducted thorough exploratory analysis to understand the underlying patterns and relationships in the data. This analysis was pivotal in selecting the most informative features for the models.\n\n\n\nPenguins dataset quantitative features pairplot\n\n\nThe EDA began with grouping the dataset by species and sex to compute summary statistics for each group across all quantitative features. To visualize the relationships between variables, we utilized Seaborn’s pair plot tool, color-coding each of the three penguin species. This visualization helped us identify significant clusters, indicating strong differentiation potential between species based on certain feature combinations.\n\n\n\nHistograms for Culmen (penguin beak) length and depth, grouped by species, to highlight group differences and a potential way to identify species given these measurements.\n\n\nNotably, the relationships between culmen length vs. flipper length, body mass vs. culmen length, and culmen depth vs. culmen length exhibited distinct clusters that were promising for classification. Additionally, histograms for culmen length and culmen depth—grouped by species—revealed unique patterns. These distributions showed some overlap when considered individually but, when combined, suggested a high potential for accurately classifying species. We also examined these features split by sex, revealing further distinctions in measurements that could enhance our model’s predictive accuracy. The combination of culmen length and depth, in particular, emerged as critical: distinguishing between Adelie and the combined group of Chinstrap/Gentoo by culmen length, and between Gentoo and the combined group of Adelie/Chinstrap by culmen depth. This structured approach not only facilitated a thorough understanding of the dataset but also ensured that our machine learning models were built on a solid foundation of clean and relevant data.\n4. Feature Selection\n\nInformed by our EDA, we moved to feature selection, aiming to identify a compact set of features that could effectively predict penguin species. Given the patterns observed, we chose to focus on two quantitative features—culmen length and depth—and one qualitative feature—sex—as our primary predictors.\nTo refine our selection and validate the effectiveness of these features, we devised a function named comb_score. This function systematically tested combinations of these features across our three chosen models: Multinomial Logistic Regression, Random Forests, and Support Vector Machines. Employing cross-validation as part of our strategy allowed us to mitigate overfitting and ensure robustness in our model’s performance. Cross-validation was particularly vital, as it provided a more generalized understanding of model accuracy across multiple subsets of the data, rather than relying solely on a single train-test split.\nThis approach not only streamlined our feature set but also reinforced our model’s capacity to generalize well to new data, an essential aspect of successful machine learning applications. By the guidelines of the project, we were to select 2 quantitative variables and 1 qualitative variable. From the results of running this function, we found that the three most appropriate variables to include in the model were ‘Culmen Length’, ‘Culmen Depth’, and ‘Sex’.\n5. Modeling\nTo analyze the data, we employed three distinct machine learning models using the Sci-kit Learn library: Multinomial Logistic Regression (MLR), Random Forest, and Support Vector Machines (SVM). Each model was evaluated for its effectiveness in classifying the species of penguins based on the selected features.\n\nMultinomial Logistic Regression (MLR): We began with the MLR model due to its robustness in handling multiclass classification problems. After training the model, we utilized a confusion matrix to assess its performance. The confusion matrix demonstrated perfect classification accuracy on the test set, with a cross-validation score of 0.988. Furthermore, we plotted decision regions to visualize the classification boundaries created by the model. These plots revealed that most data points were correctly classified, with only a few outliers, emphasizing the model’s overall high accuracy and reliability.\n\n\n\n\nDecision regions as predicted by multinomial logistic regression model, colored by species.\n\n\n\nRandom Forest: Our next model was the Random Forest classifier. After training, similar evaluations were conducted. The confusion matrix indicated that the Random Forest model successfully predicted the species of 63 out of 64 penguins in the test set, only misclassifying a single Gentoo penguin as a Chinstrap. The cross-validation score for this model was 0.981. Decision region plots were again used to visualize the model’s performance, showing a high degree of accuracy, with minimal misclassification except for the noted outlier.\n\n\n\n\nDecision regions as predicted by randon forest model, colored by species.\n\n\n\nSupport Vector Machines (SVM): Finally, we trained the SVM model. This model yielded a cross-validation score of 0.827, significantly lower than the other two models. The confusion matrix revealed several misclassifications, particularly misidentifying 7 Gentoo penguins as Chinstrap. This issue was further explored through decision region plots, which highlighted a large overlap in the prediction regions, especially where the SVM used culmen depth as a key feature. It became evident that the model struggled with overlap in feature distributions, particularly for Gentoo penguins with culmen depths less than approximately 18-19 mm, leading to these misclassifications. Each model’s decision regions provided critical insights into how effectively each algorithm could delineate between species based on the given features. This comparison highlighted strengths and weaknesses in how each model handled the complexity of the dataset, guiding our ultimate choice of the best performing model for the final application.\n\n\n\n\n\nDecision regions as predicted by support vector machines model, colored by species.\n\n\nResults\n\nMultinomial Logistic Regression (MLR) The Multinomial Logistic Regression model achieved a cross-validation score of 0.988, indicating high accuracy in predicting penguin species based on culmen length, culmen depth, and sex. The confusion matrix confirmed that the model correctly classified all penguins in the test dataset. Despite a few points misclassified as outliers, the decision regions plot demonstrated that the model performs robustly across the dataset. This suggests that the MLR model is not overfitting, as it maintains consistent performance across training, cross-validation, and testing datasets, indicating good generalization to new data. Possible improvements could include expanding the dataset and incorporating more predictive features to enhance the model’s accuracy further.\nRandom Forest The Random Forest model reported a cross-validation score of 0.981, showcasing its effectiveness in species classification using the same features as MLR. It misclassified only one penguin in the test set, suggesting it is almost as accurate as the MLR model. The decision regions plot indicated no signs of overfitting, with stable performance across different data splits. This model’s generalizability could potentially be improved through hyperparameter tuning, such as GridSearch or Bayesian optimization, to optimize performance.\nSupport Vector Machines (SVM) The Support Vector Machines model lagged behind the other two, with a cross-validation score of 0.827. It incorrectly predicted the species of 7 out of 64 penguins in the test set, primarily confusing Gentoo penguins as Chinstrap. This issue was visible in the decision regions plot, where the model showed significant overlap in species classification. Despite its lower performance, the SVM model did not exhibit signs of overfitting and performed consistently across the training and testing datasets. Improvement could be achieved by expanding the number of qualitative variables used for prediction, which preliminary tests suggested might enhance accuracy.\n\nOverall Performance and Recommendations:\nThe MLR and Random Forest models both achieved near-perfect prediction accuracy on the test data, making either model a strong candidate for practical applications. However, given its slightly higher cross-validation score and simpler structure, the MLR model is recommended as the primary choice. Its simplicity suggests better generalizability and lower computational overhead compared to the more complex Random Forest model.\nIn conclusion, while all three models performed commendably, the Multinomial Logistic Regression model, using culmen length, culmen depth, and sex as predictors, is selected as the optimal model for classifying penguin species due to its high accuracy and model simplicity.\nChallenges\nThroughout the project, we faced several challenges that tested our problem-solving and analytical skills. One of the primary challenges was working with these models in python, as they were all brand new to us as students. We conducted a lot of research and consulted the documentation from sci-kit learn heavily. Another challenge was determining the best methods for feature selection and model evaluation, especially in balancing model accuracy with the risk of overfitting. To tackle this, we were able to plot the decision regions of the model, which also gave us a lot of helpful insight into how the models were making their classifications, and where the cutoff for the features was. These challenges necessitated a thorough exploration of various statistical techniques and collaborative problem-solving to ensure the integrity and reliability of our findings.\nTeamwork\nThe success of this project was largely due to effective teamwork and collaborative effort. All team members were actively involved in every phase of the project, from data acquisition and preparation to model evaluation and final discussions. In the initial stages, we jointly worked on cleaning the data, which involved rigorous discussions on handling missing values and deciding which features to modify or remove. During the data visualization phase, each of us contributed by coding at least one plot or table, ensuring diverse input in the discussion and interpretation of results.\nFeature selection was a collective effort where we debated various approaches and jointly developed the cross-validation scoring function, primarily coded by Chen and Lucas. Model fitting and analysis were also collaborative, with Ethan (myself) taking the lead on coding the decision regions plots. We collectively analyzed the outputs, including confusion matrices and the implications of misclassifications by each model. Our final decision on the model selection was made unanimously, reflecting our cohesive approach to research and problem-solving.\nConclusion\nThis project not only enhanced our technical skills in data science and machine learning but also strengthened our ability to work as a team. Throughout the project, we successfully navigated challenges through mutual support and shared knowledge, which was crucial in achieving our objectives. The experience has prepared us well for future collaborative projects and professional challenges in the field of data science. Read my full report of the project here. And just for fun for reading this far, here is a super cute video of Gentoo Penguins building nests."
  },
  {
    "objectID": "projects/Sentiment_tweets/index.html",
    "href": "projects/Sentiment_tweets/index.html",
    "title": "Mental Gymnastics",
    "section": "",
    "text": "Simone Biles completing a beam routine at the Tokyo 2020 Olympics, days before dropping out due to mental health concerns."
  },
  {
    "objectID": "projects/Sentiment_tweets/index.html#introduction",
    "href": "projects/Sentiment_tweets/index.html#introduction",
    "title": "Mental Gymnastics",
    "section": "Introduction",
    "text": "Introduction\nIn recent years, the intersection of mental health and athletic performance has garnered significant attention, particularly within the context of high-profile athletes. Recent discussions are challenging existing stigmas and promoting a new culture of openness and support. This study focuses on analyzing public sentiment towards the mental health of athletes by examining tweets posted about Simone Biles after dropping out of the Olympic competition in Tokyo, following mental health concerns.\nSimone Biles’ public discourse provides a rich playground for exploring societal attitudes towards mental health in the sports domain, using twitter as proxy for public response. Utilizing natural language processing techniques (NLP), this report examines the nuances of public opinion, shedding light on prevalent themes and sentiments expressed on social media. Understanding these perspectives is crucial for addressing stigma and promoting mental health awareness among athletes. This study aims to contribute to the broader conversation on mental health in sports, offering insights into the public’s response to athletes’ mental health challenges. Click here to find the gihub for the project where all the code and documentation can be found, and click here to skip over the methodology and go straight to the results.\n\nProject Overview\nThe primary objective is to understand how public discourse, as seen in Twitter social media, frames mental health issues within the realm of professional international sports. We use sentiment analysis to capture the attitude of the public’s reaction. We then use topic modelling to identify common themes present in the tweets, and finally word vectorization to map topics to words and emotions."
  },
  {
    "objectID": "projects/Sentiment_tweets/index.html#methodology",
    "href": "projects/Sentiment_tweets/index.html#methodology",
    "title": "Mental Gymnastics",
    "section": "Methodology",
    "text": "Methodology\n\nData Collection\nThe dataset was compiled from public tweets using the Twitter API, isolating tweets mentioning gymnastics during the 2020 Summer Olympics. The collection period spanned from July 15 to August 14, 2021, capturing the timeline of Simone Biles’s participation and subsequent withdrawal. The dataset contains around 16.5K tweets. The features present in this dataset include: the textual content of each tweet, any entities present (hashtags, mentions, urls, etc.), the time posted, and the unique twitter ID of both the author and the tweet.\nNotably, any information related to engagement metrics, i.e. likes, comments, replies, and retweets, is not part of the dataset. This required us to direct our analytical focus towards natural language processing due to the data’s qualitative nature.\nThe cleaned data consisted of the following fields:\n\n\n\nVariable\n\n\nDescription\n\n\n\n\nText\n\n\nContent of the tweet\n\n\n\n\nEntities\n\n\nVarious entities mentioned in the tweet, such as hashtags and annotations\n\n\n\n\nTime\n\n\nThe time the tweet was posted\n\n\n\n\nOther\n\n\nOther information, e.g. unique tweet ID, author ID, and edit history were not utilized in this analysis\n\n\n\n\n\nExploratory Data Analysis\nWe began our analysis by exploring the dataset to understand the dataset on a broad level before diving into an analysis. We began by creating a word cloud of the tweet textual data.\n\n\n\nFig 1. Word Cloud\n\n\nOlympics, gymnastics, and Simone Biles are all central to this word cloud, indicating a high volume of tweets that contained these words. Other recurrent terms such as “tokyo2020,” “team,” “gold,” and “sport” further characterize the dataset’s focus around gymnastics and the Olympic Competition.\nWe then looked at the number of tweets per hour and how they evolved over time after Simone Biles made the announcement to drop out of the Olympics. The team used an eight-hour rolling mean to smooth out the curve over a longer time period while still retaining the shape of the data.\n\n\n\nFig 2. Tweet volume per 8 hours.\n\n\nWe see a clear spike right after her announcement, indicating a public response on the day she decided to drop out; however, we also see the number of tweets decrease relatively quickly after August 27, returning to what seems to be normal olympic tweet volume after about a week, and then to low tweet activity after just 2 weeks. This suggests there was not a sustained public reaction.\nFinally, we looked at the top 10 most common hashtags present.\n\n\n\nFig 3. Bar Chart of Hashtags.\n\n\nWe can see again an strong focus on gymnastics, with the olympics, and Simone Biles also being important hashtags. We see the first mention of mental health in the 9th most common hashtag, indicating that it is a relevant topic to this dataset, but appears not to be the primary focus of the tweets. With a better understanding of the content of the data, we move on to natural language processing.\n\n\nNatural Language Processing\n\nPreprocessing\nTo prepare for NLP, we further preprocessed the tweet data to standardize it, focusing on the pure textual content. We followed preprocessing protocol by first removing all punctuation and special characters, as well as any stop words like “the” and “and” which don’t carry meaningful information. Tweets were then lemmatized, breaking down words to their root form (e.g. ‘flipping’ \\(\\rightarrow\\) ‘flip’), which typically improves NLP results. We did our best to remove junk tweets, and decided to remove all links and url patterns from the text as well, to focus on the textual content of each tweet.\n\n\nSentiment Analysis\nFor sentiment analysis, we employed the Valence Aware Dictionary and sEntiment Reasoner (VADER) tool, which is well-suited for social media text due to its consideration of contextual polarity and intensity. VADER assigns each tweet a sentiment score based on a predefined lexicon. The sentiment score ranges from -1 to 1, where:\n\nNegative sentiment: Scores closer to -1 indicate negative sentiment.\nNeutral sentiment: Scores around 0 indicate neutral sentiment.\nPositive sentiment: Scores closer to 1 indicate positive sentiment.\n\nEach tweet in the dataset was processed through the VADER tool to generate sentiment scores. The distribution of sentiment scores across the dataset was analyzed to identify overall trends and patterns. This analysis included calculating the proportion of positive, negative, and neutral tweets. The sentiment analysis results set the foundation for further investigation into the public’s perception of athletes’ mental health and provided a contextual basis for the subsequent topic modeling.\n\n\nNon-negative Matrix Factorization\nTo further understand the themes and discussions within tweets about Simone Biles, we employed topic modeling, a technique designed to discover abstract topics within a collection of documents. This study utilized Non-Negative Matrix Factorization (NMF), a method that is particularly effective for high-dimensional text data, providing clearer and more interpretable topics.\nWhile many topic modelling techniques were initially tested, like Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA), NMF was chosen for its robustness in handling large text datasets and its ability to produce easily interpretable topics. NMF works by factorizing the term-document matrix into two lower-dimensional matrices: a term-topic matrix and a topic-document matrix. Each document (tweet) is represented as a mixture of topics, and each topic is represented as a mixture of terms.\nImplementation:\n\nLibrary: The NMF model was implemented using Python’s Scikit-learn library.\nParameter Selection: The number of topics was determined by evaluating the coherence scores and conducting manual inspections to ensure meaningful and distinct topics.\nProcess: The preprocessed tweet data was vectorized using Term Frequency-Inverse Document Frequency (TF-IDF) to create the term-document matrix. This matrix was then decomposed using NMF.\n\nThe resulting topics were analyzed and labeled based on the most representative terms and example tweets for each topic. Each topic was defined by a set of high-weighted words, providing insights into the key themes discussed in relation to Simone Biles’ mental health."
  },
  {
    "objectID": "projects/Sentiment_tweets/index.html#results",
    "href": "projects/Sentiment_tweets/index.html#results",
    "title": "Mental Gymnastics",
    "section": "Results",
    "text": "Results\nThis allowed us to produce a histogram of sentiment scores for all tweets in the dataset.\n\n\n\nFig 4. Histogram distribution of sentiment scores for tweets.\n\n\nInterestingly, this\n.\n. .\n.\n.\n.\n. .\n.\n.\n.\n.\n. . . . . . . . . . . . .\nTo prepare the data for analysis we first extracted the entities from each tweet to store them individually to make analysis easier. Many features of the dataset were not utilized in this analysis - for example, columns relating to unique tweet and author ID numbers, IDs of referenced tweets, information about any withheld content, and the edit history of tweets.\nUtilizing TextBlob, a python sentiment library, we were able to assign a sentiment score to each tweet, acting as an estimate of the overall positive or negative attitude. This is achieved with a word lexicon that assigns a score to most english words, and those scores are averaged to give an estimate of the overall sentiment of a tweet. With this we were able to give every tweet a sentiment score and analyze the changes and patterns in sentiments over time and within different groups.\nNMF: Understanding the Output: - Top Words: The top words for each topic were examined to understand the main themes. - Example Tweets: Representative tweets were reviewed to provide context and validate the relevance of the topics. - Topic Distribution: The prevalence of each topic across the dataset was analyzed to identify dominant themes and trends over time."
  },
  {
    "objectID": "projects/Super_mario_RL/index.html",
    "href": "projects/Super_mario_RL/index.html",
    "title": "Super Mario Reinforcement Learning",
    "section": "",
    "text": "Original Super Mario Bros.\n\n\n\nIntroduction\nSuper Mario Bros is legendary. Despite not playing it myself in my childhood, I grew up on it’s legacy. I had decided I was going to tackle a project with AI, wanting to challenge myself to learn about deep learning by doing it, but when deciding on a specific challenge, I wanted something to represent how this challenge with AI made me feel. Super Mario Bros. is that challenge. It feels monumental, unwavering and bold in status, despite being so simple, as if it, as a game, knew what it’s legacy would be.\nIt felt fitting, dare I say poetic, to choose this classic game with such a powerful status: it’s straightforward, yes, but conquering it with AI still presents a significant challenge, and, much like this game became larger than itself in a mega-universe of games and lore, this project feels like the beginning of my journey to learn and understand AI. You’ll see that I was not able to fully achieve what I wanted, but think of this project as a starting point and a symbol of all the bigger things to come, the first footsteps taken in search of a flagpole out in the infinite distance.\n\n\nProject Overview\n\nUnsupervised Learning\nThe framework we used for out AI is called unsupervised learning. It is a machine learning approach where the AI learns to achieve a task without a human-defined “optimal” solution or stragey. It is different from supervised learning, where we as the human trainer want the AI to learn to mimic some human behavior, like identifying handwritten digits or something. In supervised learning, the AI knows what the right answer is. It might have guessed that that weird looking squiggle was a 2, but it knows after its prediction that it was actually a 5.\nBoth supervised and unsupervised learning are useful for different tasks, but unsupervised learning is much more open-ended in nature, and in some ways more exciting. Without being chained to learn a strategy that humans might think is optimal, it’s free to explore the game and come up with its own idea of optimal strategy.\nMy favorite example of this comes from the game of Go and the AI that learned to master it, AlphaGo. Go is an ancient game, originating in east-asia. Wildly more complex than chess, humans have spent the last 2000 years developing what they thought was an “optimal strategy.” Enter AlphaGo, an unsupervised AI that taught itself to play Go, that learned completely unconventional, seemingly illogical strategy. It famously defeated the world’s best Go player, Lee Sedol, 4-1 in a highly publicized 5-game tournament. For anyone who hasn’t seen the documentary, I highly recommend it, of the same name: AlphaGo. But you should definitley finish reading this first.\n\n\n\nAlphaGO AI vs. Lee Sedol in highly publicized tournament.\n\n\n\n\nProject Goals\nAnyways, I am fascinated by that story and to me it represents the enormous potential of AI, of which I believe we are just dipping into the surface of right now. I wanted an AI that might teach me something, if it learns a better strategy for playing Super Mario Bros. With that, we set out two goals for this project:\n\nTrain an AI to beat the first level of Super Mario Bros. better than me (SuperHuman).\nTrain this AI in such a way that it is able to develop a general strategy—i.e. if you were to drop it in a new unseen level, it would be able to beat it.\n\n\n\n\nMethodology\n\nMathematical Theory of Reinforcement Learning\nBefore diving into the implementation of our AI, our team dedicated significant time to understand the mathematical foundations of reinforcement learning algorithms. This foundational knowledge was crucial to understanding how to implement our model in code.\nAt its core, reinforcement learning involves an agent that learns to make sequential decisions by interacting with an environment. The agent is in a constant cycle of performing an action, receiving rewards or penalties from that action, then picking a new action and repeating. Over time the AI learns to take actions that maximize its rewards. The key concepts include:\n\nAgent: The learner or decision-maker, the AI ‘Player’ in this context.\nEnvironment: Everything external the agent interacts with, in this case the stage or level.\nState (\\(s\\)): A representation of the current situation of the agent, i.e. his place in the enviroment.\nAction (\\(a\\)): A choice the agent can make.\nReward (\\(r\\)): Feedback from the environment based on the action the agent has taken.\nPolicy (\\(\\pi\\)): A strategy that the agent employs to determine what actions to take based on states.\nValue Function (\\(V(s)\\)): The expected cumulative reward for being in state \\(s\\) and following a policy \\(\\pi\\).\nQ-Value Function (\\(Q(s, a)\\)): The expected cumulative reward for taking action \\(a\\) in state \\(s\\) and following a policy \\(\\pi\\).\n\nSo what we call learning for the AI is actually the agent finding a policy that maximizes its total expected reward, often referred to as the return. Here, the agent is guided by the Q-value function that it learns, which, very broadly, it uses to predict how much reward it expects to receive from taking actions in some state. It then chooses to take the action with the highest predicted reward, and that becomes it’s policy.\nThe fundamental algorithm here is Q-Learning, where the agent learns to approximate the true Q-value function iteratively using the Bellman equation:\n\\[ Q(s, a) \\leftarrow Q(s, a) + \\alpha \\left( r + \\gamma \\max_{a'} Q(s', a') - Q(s, a) \\right) \\]\nWhere \\(\\alpha\\) is the learning rate, \\(\\gamma\\) is the discount factor, and \\(s'\\) and \\(a’\\) are the next state and action, respectively. This algorithm uses future rewards and some hyperparameters that we can tune to make updates to the Q-value function that make it better at predicting rewards.\nThe details of this function really aren’t important. The key takeaway is that we have a way to update our Q-value function to get better and better at predicting rewards for our agent, allowing it to make better choices about what action to take to get it closer to the flagpole.\nA small caveat I will make right here is that we actually want to use a slightly more complicated equation since our model uses a neural network to approximate the Q-value function. The math here is extremely complicated and beyond me, but people smarter than me have shown that it is better to use this equation:\n\\[ Q(s, a) \\leftarrow Q(s, a) + \\alpha \\left( r + \\gamma Q_{\\text{target}}(s', \\arg\\max_{a'} Q_{\\text{online}}(s', a')) - Q_{\\text{online}}(s, a) \\right) \\]\nThis approach mathematically stabilizes training by using a separate neural network to predict future rewards (called the target network) from the one that chooses actions for mario (the online network). This separation helps improve the accuracy and reliability of our AI agent’s learning process.\n\n\nImplementation Framework\nThe implementation of this project in code follows this extremely helpful and detailed tutorial on youtube, from Sourish Kundu. This video was amazing, going over the theoretical math that I talked about above, and showing how to actually implement that theoretical framework in code.\nThe implementation involved setting up the environment with OpenAI’s Gym, designing the neural network architecture, and developing the training loop to iteratively update the Q-values and improve the agent’s performance. We made sure to adapt and expand upon the concepts introduced in the video to tailor the project to our specific goals and requirements.\n\n\nArchitecture\nOur AI training framework for Super Mario Bros follows a structured and modular approach, integrating several key components necessary for the training process. The architecture includes the neural network, the agent-environment interaction, and various simplifications to streamline the learning process. Here’s an overview of the framework and key components:\nNeural Network\nThe core of our implementation is the neural network that processes game frames and predicts the Q-values for possible actions. We used a Convolutional Neural Network (CNN) due to its effectiveness in extracting spatial features from images, crucial for understanding the game environment.\nConvolutional Layers: These layers process input frames to detect features like edges, textures, and objects. By applying what are called convolutional filters, the network learns to recognize patterns such as enemies, obstacles, and movements within the game. Fully Connected Layers: After the convolutional layers, fully connected layers combine the extracted features and predict the Q-value rewards for each possible action. The final output layer provides the Q-values for the agent’s action choices, allowing the agent to select the action with the highest predicted rewards.\nTraining Algorithm\n\nAgent: The agent interacts with the game environment, making decisions based on the state of the game and updating its knowledge through the training algorithm.\nEpsilon-Greedy Policy: To balance exploration and exploitation, we used an epsilon-greedy approach. Initially, the agent is heavily biased to explore the environment by taking random actions (high epsilon), which will lead mario to try many new strategies at the beginning of training. As training progresses, epsilon decreases, and the agent increasingly exploits the policy it has learned up to this point by choosing actions with the highest predicted Q-values.\nReplay Buffer: The agent stores its experiences (state, action, reward, next state) in a replay buffer. This allows the network to learn from past experiences and break the correlation between consecutive states, leading to more stable training.\nDouble Q-Learning: In the DDQN algorithm, we maintain two neural networks – the online network for selecting actions and the target network for evaluating them. Periodically updating the target network with the weights of the online network reduces overestimation and stabilizes learning.\n\nSimplification Choices\nTo make the training process feasible and efficient, we incorporated several simplification choices:\n\nPreprocess Frames: We preprocess the game frames using wrappers to reduce computational complexity and simplify training. A SkipFrame wrapper reduces the frequency of updates by repeating the same action for a fixed number of frames. Frames are converted to grayscale to reduce the amount of data the network must process. They are resized to a smaller, standardized size (84x84 pixels) to decrease computational load. And finally, consecutive frames are stacked to provide temporal context, which helps the agent understand movement and changes in the environment.\nLimited Action Space: We restricted the agent’s action space to a simplified set of actions (e.g., moving right, jumping) to focus on the essential movements needed to navigate the level. This reduces the complexity of the decision-making process and speeds up learning, though it does limit flexibility of the model as Mario is only allowed to perform movements that move him towards the flagpole.\nReward Structure: The reward system incentivizes the agent to progress through the level by awarding positive rewards for moving right and penalizing it for standing still or dying. This straightforward reward structure guides the agent towards the main goal of completing the level.\n\nBy combining these components and simplification choices, our implementation effectively trains an AI agent to play and beat the first level of Super Mario Bros. The modular design allows for easy adjustments and extensions, making the framework versatile for various reinforcement learning tasks.\n\n\n\n\nResults\nThe training process was very slow, due to the nature of unsupervised learning. Our AI agent faced a lot of challenges in training, initially making random decisions, and slowly but surely through training, finding a policy that worked. Initially, the model was very stupid. A big hurdle that we didn’t see coming were that the tall pipes were actually a big issue to jump over. These pipes require Mario to hold down the jump button for the maximum amount of time. With purely random button presses at the beginning of training, the chance of him holding jump for this long was evidently pretty unlikely. This would be no problem for a human player who can make the connection that the tall pipe requires a tall jump to get over it, but alas, the baby AI was not as capable.\n\n\n\n\n\nBut, through training, the AI was learning a strategy, and eventually, after almost 100 hours of training and 50,000 iterations, our AI agent was successfully beating the first level of Mario.\n\n\n\n\n\nSo, he’s still getting stuck on the pipe. But at least he is beating the level! So he’s not perfect. But there’s still a whole lot of improvement from that top video, so he is learning. He’s not perfect but I love him.\n\n\n\nReflections\nThis project was a pretty big undertaking for us. We faced several significant challenges throughout this project, which also provided valuable learning experiences. Our initial lack of experience with coding a reinforcement learning algorithm posed a steep learning curve. Additionally, training for this model was extremely computationally intensive, and we are all students who need to use our laptops for school, so there wasn’t as much training for the model as there could have been.\nLooking back at our goals, we weren’t able to achieve everything we set out to. But, we were able to get Mario to successfully beat the first level! So that is definitely something, and honestly with how hard this project proved to be, I’m very happy with that.\nThis project significantly enhanced my skills in coding, reinforcement learning, and neural network architectures. I can say that I know so much more about deep reinforcement learning, coding neural networks, and working with APIs to interact with other interfaces.\n\nImprovements to the Model\nTraining this model for longer would have a huge benefit, as it would allow Mario to become even better at understanding his environment and making decisions for actions to take. Right now, he is still seemingly doing erratic, random movements.\nAdditionally, the full move set would give Mario more flexibility in the choices he was making, though, it would take much more training time.\n\n\n\n\nConclusion\nIn this project, we successfully trained an AI agent to play and beat the first level of Super Mario Bros using a Double Deep Q-Network (DDQN) algorithm. This achievement showcases the power and potential of reinforcement learning, demonstrating how an agent can learn complex tasks through interaction with its environment and iterative improvement.\n\nSummary\n\nIntroduction to Reinforcement Learning: We began by grounding ourselves in the mathematical foundations of reinforcement learning, understanding key concepts like the Q-value function, Bellman equation, and the differences between supervised, unsupervised, and reinforcement learning.\nImplementation Framework: Our implementation was structured around a robust neural network architecture, leveraging convolutional layers to process game frames and fully connected layers to predict Q-values. The agent utilized an epsilon-greedy policy to balance exploration and exploitation, with experiences stored in a replay buffer to stabilize training.\nChallenges and Solutions: We navigated several challenges, including our initial lack of experience with coding advanced reinforcement learning algorithms, long training times, and diagnosing bugged code. Systematic debugging, incremental progress, and efficient use of computational resources were key to overcoming these hurdles.\nSkills Developed: This project significantly enhanced our coding proficiency, deepened our understanding of unsupervised machine learning, and provided practical experience in designing and optimizing neural network architectures.\nTraining Process and Results: The agent’s performance improved over successive episodes, with increasing total rewards indicating effective learning. The final model, as showcased in the embedded video, successfully navigates the game level and reaches the goal, demonstrating the effectiveness of our approach.\n\n\n\nRecommendations for Improvement\nGiven more time and resources, there are several ways to enhance this project further:\n\nExtended Training Time: Increasing the training duration and utilizing more powerful computational resources could further improve the agent’s performance and stability. Access to high-performance GPUs or cloud-based computing platforms would be beneficial.\nAlgorithm Optimization: Exploring and implementing more advanced reinforcement learning algorithms, such as Proximal Policy Optimization (PPO) or Asynchronous Advantage Actor-Critic (A3C), could lead to better performance and more efficient learning.\nHyperparameter Tuning: Conducting a thorough hyperparameter tuning process using techniques like grid search or Bayesian optimization could optimize the training process and improve the agent’s learning rate, discount factor, and exploration strategy.\nEnvironment Complexity: Expanding the complexity of the game environment by including additional levels or more dynamic elements could provide a more rigorous test of the agent’s capabilities and adaptability.\nModel Enhancements: Incorporating techniques like transfer learning, where the agent is pre-trained on simpler tasks before tackling the main game, could accelerate learning and improve performance. Additionally, using more sophisticated neural network architectures, such as deeper convolutional networks or recurrent neural networks, could enhance the agent’s ability to process and understand the game environment.\n\nThis project has been a valuable journey into the world of reinforcement learning, providing practical insights and demonstrating the potential of AI in solving complex tasks. With further improvements and optimizations, there is immense potential to push the boundaries of what our AI agent can achieve.\nThank you for following along with this journey. And thank you again to Sourish Kundu for his excellent video on training an unsupervised deep learning Mario AI. The link to the github for this project is here."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Mental Gymnastics\n\n\n\n\n\n\nsentiment analysis\n\n\nlinguistics\n\n\ntopic modelling\n\n\n\nAnalysis of public stigma in response to athletes’ mental health through tweets about Simone Biles during the 2020 Olympics.\n\n\n\n\n\nMar 22, 2024\n\n\nElena Bateman, Priyanka Iragavarapu, Rebekah Limb, Alyssa Lung, Misha Reiss, Ethan Warren\n\n\n\n\n\n\n\n\n\n\n\n\nSuper Mario Reinforcement Learning\n\n\n\n\n\n\nmachine learning\n\n\nneural network\n\n\ndeep reinforcement learning\n\n\n\nTraining an AI to play and beat Super Mario Bros. with unsupervised deep reinforcement learning.\n\n\n\n\n\nMar 13, 2024\n\n\nBree Chen, Tony Lei, Alyssa Liu, Ethan Warren\n\n\n\n\n\n\n\n\n\n\n\n\nPenguins Classification\n\n\n\n\n\n\nmachine learning\n\n\nscience\n\n\nunsupervised learning\n\n\n\nTraining a classical machine learning model to predict a penguin’s species from physical characteristics.\n\n\n\n\n\nJun 2, 2022\n\n\nChen Guan, Lucas MacHardy, Ethan Warren\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "About Me!",
    "section": "",
    "text": "Here is some text about me."
  }
]